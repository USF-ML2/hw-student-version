{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c6360403d7c651183520c08603fcf38",
     "grade": false,
     "grade_id": "cell-7bb7f8506dfae415",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homework 2\n",
    "**Instructions:**\n",
    "- Submit your code to github by the deadline.\n",
    "- DO NOT change paths (-3 points).\n",
    "- DO NOT submit data to github (-2 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "faa7d57db15637b9b55b67f9808b36b7",
     "grade": false,
     "grade_id": "cell-963eb775c60d3928",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60c90f6e90c22dc6ebda523037854db1",
     "grade": false,
     "grade_id": "cell-4c6cc62f82ecc43c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 1: log loss\n",
    "**(a)** You have a classification problem with 3 classes: \"cat\", \"dog\", \"bird\". For your test observation is a \"dog\". Your model give you the following prediction for that observation (0.1, 0.5, 0.4). What is the accuracy? What is the log loss?\n",
    "\n",
    "**(b)** Suppose that you are submitting to a Kaggle competition. You are solving a binary classification task being evaluated by log loss metric. You suspect train and test target distributions are different, you submit a constant predition of 0.3 and to the public LB and get a score of 1.01. Mean of target variable in train is 0.44. What is the mean of target variable in public part of test data? Explain how you derive the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9326fdec6b371a1eb9b833261a7e8247",
     "grade": true,
     "grade_id": "cell-c82df83e145eadb0",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2244343e72ff6bce546993f3fef1aac5",
     "grade": true,
     "grade_id": "cell-a2638ff2cc953f08",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b3f0e633f014a2ebb5801c768891daa1",
     "grade": true,
     "grade_id": "cell-d9101ca9ed47f098",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab665ee9f0504368b7cb36d7ca41be20",
     "grade": false,
     "grade_id": "cell-9aed1b87140d15c7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 2: AUC\n",
    "Compute AUC score by hand with the formula explained in class for the following dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7c0e0d0db32cc22cded8f253620c101c",
     "grade": false,
     "grade_id": "cell-d54a5c5492c74c18",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame({\n",
    "        'prediction': [0.1, 0.5, 0.95, 0.99, 0.8, 0.4, 0.03, 0.44, 0.2],\n",
    "        'y': [1, 0, 1, 1, 1, 1, 0, 0, 0]})\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d2cfa48c353b5a795097092af3a66433",
     "grade": false,
     "grade_id": "cell-e2d5af5c0b163de9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "AUC is the probability a randomly-chosen positive example is ranked more highly than a randomly-chosen negative example. It can be computed as the ratio of\n",
    "\n",
    "$$1 - \\frac{\\text{number of pairs example wrongly ordered }}{\\text{number of pairs (positive, negative)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "32a1838d9cfd84e0120023e1a787793c",
     "grade": true,
     "grade_id": "cell-b5c4e063540eebfb",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5cc1b1bbaf5bf0763dbfdd72c0a500f2",
     "grade": false,
     "grade_id": "cell-cc56ff567f83c54c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 3: Regularized mean (target) encoding for Avazu competition\n",
    "\n",
    "For this problem you will implement a version of regularized mean encoding. We will be using the data on this Kaggle [compettion](https://www.kaggle.com/c/avazu-ctr-prediction).  \n",
    "\n",
    "**Instructions:**\n",
    "- Split data (training) into training and validation. Take the last week (7 days) of training set as validation.\n",
    "- Implement regularized mean encoding for the training set using pandas.\n",
    "- Implement mean encoding for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98c1c32735a923591ccc8354da222f26",
     "grade": false,
     "grade_id": "cell-6714619fcc6c6243",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Split train and validation \n",
    "# get sample data first\n",
    "path = \"avazu/\"\n",
    "!head -100000 $path/train > $path/train_sample.csv\n",
    "!head -100000 $path/test > $path/test_sample.csv\n",
    "data = pd.read_csv(path + \"train_sample.csv\")\n",
    "test = pd.read_csv(path + \"test_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "283db1f0a18a247feb2d9101de4df5dc",
     "grade": false,
     "grade_id": "cell-3247c5546454354b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def split_based_hour(data):\n",
    "    \"\"\" Split data based on column hour.\n",
    "    \n",
    "    Use 20% of the date for validation.\n",
    "    Inputs:\n",
    "       data: dataframe from avazu\n",
    "    Returns:\n",
    "       train:\n",
    "       val: 20% of the largest values of column \"hour\".\n",
    "    \"\"\"\n",
    "    N = int(0.8*len(data))\n",
    "    data = data.sort_values(by=\"hour\")\n",
    "    train = data[:N].copy()\n",
    "    val = data[N:].copy()\n",
    "    return train.reset_index(), val.reset_index()\n",
    "train, val = split_based_hour(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "160febfee5ae9e860499d532ea6c707b",
     "grade": false,
     "grade_id": "cell-452970eca3e65752",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Regularized mean encoding \n",
    "Here is how you do mean encoding without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cfcd19e7cc09803027236f34319a5938",
     "grade": false,
     "grade_id": "cell-77c4b82107ebcc48",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate a mapping: {device_type: click_mean}\n",
    "mean_device_type = train.groupby('device_type').click.mean()\n",
    "mean_device_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "33a2b7ea42f7250ca63e72662f7c1f80",
     "grade": false,
     "grade_id": "cell-ed1cc1dcf31b6592",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is the global click mean\n",
    "global_mean = train.click.mean()\n",
    "global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e6da1f98a3600a0e0c8d0d3f5a0b6e92",
     "grade": false,
     "grade_id": "cell-b18e26077498e310",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train[\"device_type_mean_enc\"] = train[\"device_type\"].map(mean_device_type)\n",
    "val[\"device_type_mean_enc\"] = val[\"device_type\"].map(mean_device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c7bbb2f5b95852108d0a52d3955c184",
     "grade": false,
     "grade_id": "cell-3738c83f6ed83558",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train[\"device_type_mean_enc\"].fillna(global_mean, inplace=True)\n",
    "val[\"device_type_mean_enc\"].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5027fe3d503aed56fb0b1936334d6901",
     "grade": false,
     "grade_id": "cell-a02b93e0e675fcfc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Print correlation\n",
    "encoded_feature = val[\"device_type_mean_enc\"].values\n",
    "print(np.corrcoef(val[\"click\"].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53f9c475060eb35dde22ef1fb8815531",
     "grade": false,
     "grade_id": "cell-bcfd0241d1bbc117",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "To do mean encoding with K-fold regularization you do the following:\n",
    "\n",
    "* Run a 5-fold split on train data where `mean_device_type` is computed on 4/5 of the data and the encoding is computed on the other 1/5.\n",
    "* To compute mean encoding on the validation data use the code similar to encoding without regularization. That is compute on all the training data and apply to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7a342519715706a0152213f7bd22ccc1",
     "grade": false,
     "grade_id": "cell-775e47f5b0194cbe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def reg_target_encoding(train, col = \"device_type\", splits=5):\n",
    "    \"\"\" Computes regularize mean encoding.\n",
    "    Inputs:\n",
    "       train: training dataframe\n",
    "       \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06db617336e33141cf8db2cbf18cb2a6",
     "grade": true,
     "grade_id": "cell-b4683b910e8c7ca9",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "reg_target_encoding(train) \n",
    "encoded_feature = train[\"device_type_mean_enc\"].values\n",
    "corr = np.corrcoef(train[\"click\"].values, encoded_feature)[0][1]\n",
    "assert(np.around(corr, decimals=4) == 0.0551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36df06691ec8fc0c9bc155537f014d91",
     "grade": false,
     "grade_id": "cell-72af369cd137b75b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_encoding_test(test, train, col = \"device_type\"):\n",
    "    \"\"\" Computes target enconding for test data.\n",
    "    \n",
    "    This is similar to how we do validation\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb997cc70af17c110f9f92aaab3acdc7",
     "grade": true,
     "grade_id": "cell-ec2e728bbd5de8b3",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mean_encoding_test(test, train) \n",
    "encoded_feature_mean = test[\"device_type_mean_enc\"].values.mean()\n",
    "assert(np.around(encoded_feature_mean, decimals=4) == 0.177)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "43b47a071f2f20a0196abb6d814687e2",
     "grade": false,
     "grade_id": "cell-eb09ee7786ad32c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 4: Implement other features and fit a model (10 points)\n",
    "* Implement a few more features, include:\n",
    "   * day of the week and hour\n",
    "   * mean encoding of some other features (at least two)\n",
    "   * use plots and `value_counts()` to understand the data\n",
    "\n",
    "* Fit a random forest (to the whole dataset)\n",
    "   * Do hyperparameter tunning using your validation set\n",
    "   * Report test and train log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4b2ee7b245a73446da29cd2cb69fd8e2",
     "grade": false,
     "grade_id": "cell-e5b525e48f90cc37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path = \"avazu/\"\n",
    "    data = pd.read_csv(path + \"train\")\n",
    "    test = pd.read_csv(path + \"test\")\n",
    "    return data, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "774022487d3cee6a5d3737ef7b0124a3",
     "grade": true,
     "grade_id": "cell-9ed772e2cb29616a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
